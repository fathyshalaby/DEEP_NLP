{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `en_core_web_md` model from spacy [contains pretrained GloVe vectors](https://github.com/explosion/spacy-models/releases//tag/en_core_web_md-2.2.5)\n",
    "\n",
    "Also, we include vector calculation caching, to speed up the preprocessing for successive runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from os import path\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "CACHE_FILE = \"vecors.cache\"\n",
    "MODEL_FILE = \"best.model\"\n",
    "MODEL_INFO_FILE = \"best.model.info\"\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_EPOCH = 100\n",
    "EARLY_STOPPING_EPOCHS = 3\n",
    "EARLY_STOPPING_TRESHOLD = 0.01  # diff of NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create or load vectors from cache file\n",
    "if path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"rb\") as f:\n",
    "        x_all, y_all = pickle.loads(f.read())\n",
    "    print(\"Loaded vectors and labels from cache\")\n",
    "else:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    dataset = pd.read_csv('sst5.data.txt')  # .head(1000) to only load 1000\n",
    "    documents = nlp.pipe(dataset[\"text\"].to_list())\n",
    "    x_all = list(map(lambda doc: [word.tensor for word in doc], documents))\n",
    "    y_all = (dataset[\"label\"] + 2).to_list()  # instead of -2 - 2, make it 0-4\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        f.write(pickle.dumps((x_all, y_all)))\n",
    "\n",
    "# split first into 60:40 and the 40 into 50:50 -> 60:20:20\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.4, random_state=SEED)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.5, random_state=SEED)\n",
    "\n",
    "# custom dataloader-dataset for variable length sequences, as TensorDataset only works for equal length sequences\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "\n",
    "# padding collate-function to receive batch-processable vectors\n",
    "def pad(batch):\n",
    "    x = [torch.FloatTensor(xx).to(DEVICE) for xx, _ in batch]\n",
    "    y = torch.LongTensor([yy for _, yy in batch]).to(DEVICE)\n",
    "    return pad_sequence(x, batch_first=True).to(DEVICE), y\n",
    "\n",
    "\n",
    "# build dataloaders\n",
    "train_loader = DataLoader(MyDataset(x_train, y_train), batch_size=128, shuffle=True, collate_fn=pad)\n",
    "test_loader = DataLoader(MyDataset(x_test, y_test), batch_size=1000, collate_fn=pad)\n",
    "val_loader = DataLoader(MyDataset(x_val, y_val), batch_size=1000, collate_fn=pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Processing and optimizations\n",
    "\n",
    "We chose to see if these following parameters affect the performance:\n",
    "\n",
    "* Increase/decrease the dimension of the hidden state of the RNN\n",
    "* Increase/decrease drop out rates\n",
    "* Remove Early Stopping and, instead, train the model for a fixed number of epochs.\n",
    "* Use a Bidirectional LSTM, and define document embedding as the concatenation of the last  state of forward LSTM with the last state of backward LSTM.\n",
    "\n",
    "Additionally, we performed hyperparamter search on values that were not given explicitly like number of layers, batch_size and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size, num_layers, dropout, bidirectional):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=dropout if num_layers > 1 else 0, bidirectional=bool(bidirectional))\n",
    "        self.activation = nn.Linear(hidden_size * (bidirectional + 1) * num_layers, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward Pass. Given a batch, the model first fetches the corresponding embeddings, and calculates\n",
    "        hidden states of the given sequences (documents) with the LSTM model. The last hidden state\n",
    "        of LSTM should be used as document embedding. Using document embedding, the model predicts\n",
    "        the probability distribution of the output classes through the decoder (a linear projection) and\n",
    "        softmax layer. \"\"\"\n",
    "        _, hidden = self.lstm(x)\n",
    "        hidden = hidden[-1].permute((1, 0, 2)).reshape(len(x), -1)  # use all outputs of all layers of all directions\n",
    "        hidden = self.activation(hidden)  # Decode the hidden state\n",
    "        return self.softmax(hidden)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()  # disables dropout and gradients\n",
    "    res = np.mean([float(criterion(model(x), y.long())) for x, y in loader])\n",
    "    model.train()\n",
    "    return res\n",
    "\n",
    "def train(x_train, y_train, val_loader, test_loader, nr_samples, batch_s,\n",
    "          bidir, hidden, layers, lr_e, drop, estop):\n",
    "    start = time()\n",
    "    train_loader = DataLoader(MyDataset(x_train, y_train), batch_size=batch_s, shuffle=True, collate_fn=pad)\n",
    "    # our LSTM model\n",
    "    model = LSTM(input_size=len(x_train[0][0]), num_classes=5, hidden_size=hidden,\n",
    "                 num_layers=layers, dropout=drop, bidirectional=bidir).to(DEVICE)\n",
    "    # Loss Function. Loss is calculated using Negative Log Likelihood.\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Optimization. Adam with default parameters* is used.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1 ** lr_e)\n",
    "    tq = tqdm(range(MAX_EPOCH), leave=False)\n",
    "    vlh, correct = [0], 0  # validation loss history\n",
    "    for _ in tq:\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # run training iteration\n",
    "        for xt, yt in train_loader:\n",
    "            # train_loader iterator returns a batch_size x seq_len x embedding_size list of tensors\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xt)\n",
    "            # calculate loss and\n",
    "            loss = criterion(output, yt)\n",
    "            train_loss += float(loss)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += int(pred.eq(yt.view_as(pred)).sum().item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # run validation\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss = validate(model, val_loader, criterion)\n",
    "        vlh.append(val_loss)\n",
    "\n",
    "        # statistics\n",
    "        correct /= nr_samples\n",
    "        stats = {\"corr%\": f\"{correct * 100:.2f}\", \"tr_lo%\": f\"{train_loss * 100:.2f}\", \"va_lo%\": f\"{val_loss * 100:.2f}\"}\n",
    "        tq.set_postfix_str(str(stats)[1:-1].replace(\"'\", \"\"))\n",
    "\n",
    "        if estop:\n",
    "            # Early Stopping. After each epoch or after a certain number of batches (defined as a hyperparameter),\n",
    "            # evaluate the model on the validation set. If the evaluation result improves, save the\n",
    "            # model as the best performing model so far.\n",
    "            if vlh[-1] < min(vlh[0: -1]):\n",
    "                best_model = copy.deepcopy(model)\n",
    "            # If the results are not improving after a certain number\n",
    "            # of evaluations (given as another hyper-parameter), terminate training.\n",
    "            if vlh[-1] > min(vlh[-EARLY_STOPPING_EPOCHS-1 : -1]):\n",
    "                break\n",
    "    test_loss = validate(model, test_loader, criterion)\n",
    "    print(\"\\r\", end=\"\")  # remove tqdm\n",
    "    duration = time() - start\n",
    "    stats.update({\"te_lo%\": f\"{test_loss*100:.2f}\", \"duration\": f\"{duration:.1f}\"})\n",
    "    return stats, best_model if estop else model\n",
    "\n",
    "\n",
    "if path.exists(MODEL_INFO_FILE):\n",
    "    with open(MODEL_INFO_FILE, \"rb\") as f:\n",
    "        best_info = pickle.loads(f.read())\n",
    "else:\n",
    "    best_info = {\"te_lo%\": \"-30\"} # baseline: 30%\n",
    "hyper_params = {\"batch_s\": [512, 256, 128, 64, 32], \"bidir\": [0, 1], \"hidden\": [32, 64, 128, 256],\n",
    "                \"layers\": [1, 2, 3], \"lr_e\": [2, 3, 4], \"drop\": [0.0, 0.2, 0.4], \"estop\": [1]}\n",
    "extra_params = [\"corr%\", \"tr_lo%\", \"va_lo%\", \"te_lo%\", \"duration\"]\n",
    "print(*hyper_params.keys(), *extra_params, sep=\"\\t\")\n",
    "while True:\n",
    "    hyper = {k: random.choice(v) for k, v in hyper_params.items()}\n",
    "    # print(*hyper.values(), sep=\"\\t\\t\")  # print before training for debugging purposes\n",
    "    stats, model = train(x_train, y_train, val_loader, test_loader, len(x_train), **hyper)\n",
    "    print(*hyper.values(), *stats.values(), sep=\"\\t\\t\")\n",
    "    # if the model performs better than the best, save it!\n",
    "    if float(stats[\"te_lo%\"]) > float(best_info[\"te_lo%\"]):\n",
    "        torch.save(model, MODEL_FILE)\n",
    "        best_info = stats\n",
    "        with open(MODEL_INFO_FILE, \"wb\") as f:\n",
    "            pickle.dump(best_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experimenting with Model Variations\n",
    ">In this task, we experiment with variations of the baseline architecture, defined in the previous\n",
    ">task. In general, at least 3 variations should be implemented, trained, and evaluated. In each\n",
    ">variation, only one change should be applied to the baseline architecture. In that way, the effect\n",
    ">of the change can be traced by comparing the evaluation results.\n",
    "\n",
    "To do this, we can look at the (sorted) output of the hyperparameter search log and sort it for various factors to find\n",
    "the effects of certain hyperparameters."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Log before introducing early stopping and test-validation. Output with early stopping can be found below.\n",
    "batch_s\tbidir\thidden\tlayers\tlr_e\tdrop\tcorr%   tr_lo%\tva_lo%\tduration\n",
    "512\t1\t256\t1\t3\t0\t86.66\t-86.27\t-27.4\t278.8\n",
    "64\t1\t128\t2\t3\t0\t85.3\t-85.3\t-30.38\t364.4\n",
    "128\t1\t256\t2\t3\t0.4\t83.42\t-83.31\t-29.66\t382.4\n",
    "512\t1\t32\t2\t2\t0\t83.3\t-82.99\t-28.43\t266\n",
    "256\t1\t64\t1\t2\t0\t82.09\t-81.92\t-27.73\t269.2\n",
    "512\t1\t256\t3\t3\t0\t81.25\t-81.19\t-28.86\t393.4\n",
    "128\t1\t64\t1\t2\t0\t79.03\t-78.71\t-29.06\t310.1\n",
    "512\t1\t64\t1\t3\t0\t78.21\t-77.51\t-28.08\t320.1\n",
    "512\t1\t128\t2\t3\t0\t75.93\t-75.4\t-27.24\t331.6\n",
    "128\t1\t64\t3\t3\t0.4\t75.22\t-75.06\t-27.56\t355.8\n",
    "128\t1\t32\t1\t2\t0\t75.14\t-74.82\t-28.97\t280.7\n",
    "256\t1\t64\t2\t3\t0.2\t74.01\t-73.17\t-27.68\t310.8\n",
    "32\t1\t256\t2\t4\t0.2\t70.44\t-69.45\t-27.7\t500.1\n",
    "128\t1\t32\t1\t2\t0\t70.41\t-69.87\t-28.25\t336.2\n",
    "512\t1\t128\t2\t3\t0.2\t66.3\t-66.29\t-28.32\t312.6\n",
    "128\t1\t32\t2\t3\t0.4\t66.13\t-65.97\t-29.31\t321.6\n",
    "64\t1\t256\t1\t4\t0\t64.75\t-64.22\t-28.82\t310.5\n",
    "256\t1\t32\t2\t3\t0\t64.7\t-64.62\t-28.56\t319.6\n",
    "64\t1\t256\t2\t4\t0.4\t61.26\t-60.94\t-29.57\t400\n",
    "128\t1\t256\t2\t4\t0.4\t56.84\t-56.53\t-31.72\t363.4\n",
    "256\t1\t32\t3\t3\t0.4\t52.51\t-52.24\t-29.93\t307\n",
    "512\t1\t32\t3\t3\t0.2\t50.08\t-50.05\t-31.82\t334.4\n",
    "64\t1\t32\t2\t4\t0.2\t49.16\t-49.01\t-32.11\t338.3\n",
    "256\t1\t64\t3\t4\t0.4\t48.34\t-48.28\t-32.68\t350.3\n",
    "128\t1\t32\t2\t4\t0.2\t48.31\t-48.02\t-31.06\t318.6\n",
    "256\t1\t64\t2\t4\t0.4\t47.75\t-47.43\t-32.26\t336.8\n",
    "64\t1\t32\t2\t4\t0\t47.61\t-47.73\t-30.71\t343.7\n",
    "128\t1\t128\t2\t4\t0.2\t47.24\t-47.06\t-32.71\t362.8\n",
    "128\t1\t32\t3\t4\t0\t46.73\t-46.61\t-31.53\t309.8\n",
    "256\t0\t32\t3\t4\t0\t43.22\t-43.06\t-30.52\t290.3\n",
    "256\t0\t128\t2\t4\t0.4\t43.1\t-43.06\t-30.78\t291.1\n",
    "64\t0\t32\t2\t4\t0\t42.48\t-42.47\t-29.39\t319.1\n",
    "256\t0\t64\t3\t4\t0\t42.09\t-42.11\t-31.48\t296.7\n",
    "64\t0\t32\t3\t4\t0.4\t41.98\t-41.83\t-29.96\t344.8\n",
    "256\t0\t64\t2\t4\t0.2\t41.47\t-41.39\t-30.58\t325.1\n",
    "256\t0\t32\t2\t4\t0.2\t40.62\t-40.56\t-29.05\t292.2\n",
    "512\t0\t64\t2\t4\t0.4\t40.03\t-39.97\t-30.22\t283.7\n",
    "256\t0\t64\t2\t4\t0.2\t39.64\t-39.59\t-29.75\t303.1\n",
    "32\t0\t128\t2\t4\t0.4\t39.44\t-39.08\t-31.55\t390.4\n",
    "256\t0\t32\t3\t4\t0.4\t38.68\t-38.66\t-29.72\t272.7\n",
    "32\t0\t128\t3\t4\t0.2\t38.6\t-38.23\t-30.95\t442.4\n",
    "256\t0\t256\t3\t4\t0.2\t37.81\t-37.82\t-30.91\t334\n",
    "512\t1\t32\t1\t4\t0.2\t37.64\t-34.35\t-29.96\t259.9\n",
    "64\t0\t32\t3\t3\t0.4\t33.7\t-33.51\t-28.56\t319.5\n",
    "32\t0\t256\t1\t4\t0\t33.31\t-33.23\t-30.15\t343.8\n",
    "256\t0\t32\t1\t3\t0\t32.74\t-32.55\t-28.39\t282.2\n",
    "32\t0\t32\t1\t2\t0.4\t28.01\t-27.76\t-26.49\t308.5\n",
    "32\t0\t32\t1\t2\t0.2\t27.76\t-28.36\t-26.52\t332.7\n",
    "256\t0\t32\t2\t3\t0\t27.65\t-27.61\t-26.7\t293\n",
    "32\t0\t64\t1\t3\t0.2\t27.53\t-27.3\t-26.03\t351.1\n",
    "512\t0\t64\t1\t4\t0.2\t27.25\t-28.14\t-26.56\t313.5\n",
    "128\t0\t64\t1\t2\t0\t27.17\t-27.14\t-26.6\t300.7\n",
    "512\t0\t32\t2\t4\t0.4\t27.08\t-27.24\t-26.55\t285.2\n",
    "64\t0\t128\t1\t4\t0\t26.94\t-26.96\t-26.77\t341\n",
    "64\t0\t256\t1\t4\t0\t26.89\t-26.99\t-26.72\t290.7\n",
    "512\t0\t256\t1\t3\t0.2\t26.89\t-26.91\t-26.72\t268.5\n",
    "64\t1\t64\t3\t2\t0.2\t26.89\t-26.8\t-26.72\t396\n",
    "512\t0\t64\t2\t2\t0.4\t26.89\t-26.87\t-26.72\t265.5\n",
    "128\t1\t128\t2\t2\t0.4\t26.89\t-26.82\t-26.72\t314\n",
    "128\t1\t256\t2\t2\t0.4\t26.89\t-26.91\t-26.72\t349.7\n",
    "64\t0\t256\t1\t4\t0.2\t26.89\t-26.93\t-26.72\t315.6\n",
    "512\t1\t256\t1\t2\t0.2\t26.89\t-26.88\t-26.72\t303.5\n",
    "32\t1\t128\t1\t2\t0.2\t26.89\t-26.65\t-26.72\t382.2\n",
    "128\t0\t32\t2\t2\t0\t26.89\t-26.9\t-26.72\t317.3\n",
    "32\t1\t256\t2\t2\t0\t26.89\t-26.65\t-26.72\t447.6\n",
    "32\t0\t256\t1\t2\t0.4\t26.89\t-26.65\t-26.72\t338.2\n",
    "128\t0\t32\t2\t2\t0.2\t26.89\t-26.84\t-26.72\t337\n",
    "32\t0\t128\t3\t3\t0\t26.89\t-27.51\t-26.72\t432.2\n",
    "128\t0\t128\t2\t3\t0.4\t26.89\t-26.87\t-26.72\t309\n",
    "256\t0\t128\t3\t3\t0.4\t26.89\t-26.92\t-26.72\t306.8\n",
    "64\t0\t256\t1\t2\t0\t26.89\t-26.8\t-26.72\t315.9\n",
    "256\t0\t128\t2\t3\t0\t26.89\t-26.87\t-26.72\t298.5\n",
    "512\t1\t128\t3\t2\t0.4\t26.89\t-26.86\t-26.72\t345.6\n",
    "512\t0\t256\t1\t3\t0.4\t26.89\t-26.9\t-26.72\t308\n",
    "64\t1\t64\t2\t2\t0.2\t26.89\t-26.96\t-26.72\t366.2\n",
    "256\t0\t128\t2\t2\t0.2\t26.89\t-26.86\t-26.72\t298.6\n",
    "32\t0\t32\t1\t2\t0\t26.89\t-26.65\t-26.72\t333.6\n",
    "32\t0\t64\t3\t3\t0\t26.86\t-26.62\t-26.79\t373.5\n",
    "256\t0\t32\t1\t3\t0.2\t26.63\t-26.64\t-26.01\t282.7\n",
    "128\t0\t256\t1\t4\t0.4\t26.49\t-26.49\t-25.98\t276.2\n",
    "32\t0\t256\t2\t4\t0.4\t26.38\t-26.14\t-26.03\t410.5\n",
    "64\t0\t256\t2\t2\t0\t26.32\t-26.3\t-25.99\t372.8\n",
    "256\t1\t32\t3\t2\t0\t26.32\t-26.3\t-25.99\t283\n",
    "256\t1\t128\t2\t2\t0.2\t26.32\t-26.32\t-25.99\t294\n",
    "256\t0\t256\t1\t2\t0.4\t26.32\t-26.32\t-25.99\t298.8\n",
    "64\t0\t256\t3\t3\t0.4\t26.32\t-26.22\t-25.99\t388.3\n",
    "32\t1\t128\t2\t2\t0\t26.32\t-26.09\t-25.99\t444\n",
    "128\t0\t256\t3\t2\t0.4\t26.32\t-26.31\t-25.99\t350.8\n",
    "512\t1\t256\t2\t2\t0.4\t26.32\t-26.31\t-25.99\t376.5\n",
    "32\t1\t256\t2\t3\t0\t26.32\t-26.09\t-25.99\t484.4\n",
    "512\t0\t256\t2\t3\t0.2\t26.32\t-26.36\t-25.99\t320.3\n",
    "512\t1\t256\t2\t2\t0\t26.32\t-26.31\t-25.99\t336.7\n",
    "256\t0\t128\t3\t3\t0.2\t26.32\t-26.3\t-25.99\t306\n",
    "64\t0\t256\t3\t2\t0.2\t26.32\t-26.25\t-25.99\t381.4\n",
    "64\t0\t256\t2\t2\t0\t18.24\t-18.29\t-19.14\t309.7\n",
    "32\t1\t256\t2\t2\t0\t16.13\t-15.99\t-15.09\t446\n",
    "128\t1\t128\t3\t3\t0.2\t16.13\t-16.13\t-15.11\t388.5\n",
    "64\t0\t256\t3\t2\t0.2\t16.13\t-16.12\t-15.11\t370.9\n",
    "32\t0\t256\t2\t2\t0.2\t16.13\t-15.99\t-15.11\t379.3\n",
    "\n",
    "# Outputs with early stopping and test losses:\n",
    "batch_s\tbidir\thidden\tlayers\tlr_e\tdrop\testop\tcorr%\ttr_lo%  va_lo%  te_lo%  duration\n",
    "512\t1\t256\t2\t3\t0.2\t1\t32.66\t-32.46\t-29.60\t-31.27\t12.1\n",
    "128\t1\t32\t3\t4\t0.4\t1\t33.53\t-31.41\t-28.46\t-29.06\t49.3\n",
    "64\t0\t128\t1\t4\t0.4\t1\t26.58\t-26.39\t-25.79\t-26.46\t10.6\n",
    "256\t1\t256\t3\t2\t0.4\t1\t26.32\t-26.30\t-27.53\t-25.99\t312.3\n",
    "32\t1\t128\t1\t2\t0.2\t1\t26.32\t-26.95\t-27.53\t-25.99\t298.1\n",
    "256\t1\t128\t1\t4\t0.0\t1\t35.67\t-33.98\t-29.62\t-30.70\t44.1\n",
    "128\t0\t64\t2\t2\t0.4\t1\t26.89\t-26.94\t-24.91\t-26.72\t232.3\n",
    "256\t0\t32\t2\t2\t0.0\t1\t26.32\t-26.31\t-27.53\t-25.99\t214.8\n",
    "128\t0\t128\t3\t2\t0.0\t1\t26.63\t-26.58\t-24.34\t-25.72\t6.0\n",
    "32\t0\t128\t1\t2\t0.2\t1\t26.32\t-26.09\t-27.53\t-25.99\t30.2\n",
    "512\t1\t32\t2\t4\t0.2\t1\t32.15\t-29.75\t-27.89\t-28.21\t82.6\n",
    "128\t0\t64\t3\t2\t0.4\t1\t26.89\t-26.90\t-24.91\t-26.72\t240.0\n",
    "32\t0\t128\t1\t2\t0.2\t1\t26.32\t-26.95\t-27.53\t-25.99\t258.1\n",
    "32\t0\t256\t3\t4\t0.2\t1\t26.89\t-27.46\t-24.93\t-26.72\t9.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter analysis and results\n",
    "\n",
    "We can see that without early stopping, the model seems to overfit on 100 epochs,\n",
    "as the negative training loss (roughly equivalent to the accuracy) is over 80% for the\n",
    "best runs, but the best validation losses (va_lo%) are rather in the 50%-accuracy tests.\n",
    "\n",
    "This indicates, running for a fixed number of epochs instead of early stopping could be a bad idea.\n",
    "\n",
    "Findings in hyperparameters:\n",
    "* The bidirectional processing seems to have the highest impact by far, as the best 20 results all have it enabled.\n",
    "* Lower numbers of layers also seem to be beneficial\n",
    "* The effects of dropout (only working with >1 layer) seem to be very minor or not even detectable\n",
    "* A smaller learning rate seems to limit the overfitting issue, as it produces better test-accuracies but lower train-accuracies\n",
    "* The training duration seems to be roughly [260-500] regardless of the parameters, by debugging, we found out that\n",
    " the padding and transferring the vectors to the gpu seem to make up a significant portion of time, and the effects\n",
    " of bigger batch-sizes seem to be canceled out by the on average longer batches. Obviously, early stopping strongly\n",
    " impacts training times.\n",
    "\n",
    "**Results**: None of the models perform as good as the models from previous exercises (up to 70% test accuracy)\n",
    "when validated, as they tend to overfit, but the best overfittet accuracies indicate that there is potential for\n",
    "80%+ accuracies if there was more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
